{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries and Setup Paths\n",
    "import cudf\n",
    "import cupy as cp\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "processed_train_path = '/root/autodl-tmp/projects/USL_NSL/dataset/processed/bin/KDDTrain_processed.csv'\n",
    "processed_test_path = '/root/autodl-tmp/projects/USL_NSL/dataset/processed/bin/KDDTest_processed.csv'\n",
    "train_labels_path = '/root/autodl-tmp/projects/USL_NSL/dataset/processed/bin/KDDTrain_labels.csv'\n",
    "test_labels_path = '/root/autodl-tmp/projects/USL_NSL/dataset/processed/bin/KDDTest_labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing training data...\n",
      "\n",
      "Dataset shapes after preprocessing:\n",
      "Training set: (100778, 40)\n",
      "Validation set: (25195, 40)\n",
      "Loading and preprocessing complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load and Prepare Data with Enhanced Preprocessing\n",
    "print(\"Loading and preprocessing training data...\")\n",
    "# Load features and labels\n",
    "df_train = pd.read_csv(processed_train_path)\n",
    "X = df_train\n",
    "y_train = pd.read_csv(train_labels_path)\n",
    "y_train_binary = y_train['label'].values\n",
    "\n",
    "# Split data into training and validation sets (80-20)\n",
    "X_train, X_val, y_train_split, y_val = train_test_split(\n",
    "    X, \n",
    "    y_train_binary,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_train_binary\n",
    ")\n",
    "\n",
    "# Apply RobustScaler\n",
    "robust_scaler = RobustScaler()\n",
    "X_train_scaled = robust_scaler.fit_transform(X_train)\n",
    "X_val_scaled = robust_scaler.transform(X_val)\n",
    "\n",
    "# Feature selection\n",
    "n_features = 40\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=n_features)\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train_split)\n",
    "X_val_selected = selector.transform(X_val_scaled)\n",
    "\n",
    "print(\"\\nDataset shapes after preprocessing:\")\n",
    "print(f\"Training set: {X_train_selected.shape}\")\n",
    "print(f\"Validation set: {X_val_selected.shape}\")\n",
    "print(\"Loading and preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Isolation Forest model with hyperparameter tuning...\n",
      "Starting grid search...\n",
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "\n",
      "Best parameters found:\n",
      "{'bootstrap': True, 'contamination': 0.3, 'max_features': 0.6, 'max_samples': 'auto', 'n_estimators': 300}\n",
      "Best F1-score: 0.641\n",
      "\n",
      "Retraining with best parameters on full training set...\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Initialize and Train Model with Hyperparameter Tuning\n",
    "print(\"\\nTraining Isolation Forest model with hyperparameter tuning...\")\n",
    "\n",
    "# Define parameters\n",
    "params = {\n",
    "    'n_estimators': [100, 200, 300],        # Tree number\n",
    "    'max_samples': [0.5, 0.8, 'auto'],      # Sampling ratio\n",
    "    'contamination': [0.1, 0.2, 0.3],       # Anomaly ratio\n",
    "    'max_features': [0.6, 0.8, 1.0],        # Feature sampling ratio\n",
    "    'bootstrap': [True, False]              # Whether to use bootstrap sampling\n",
    "}\n",
    "\n",
    "def custom_f1_scorer(estimator, X, y):\n",
    "    try:\n",
    "        predictions = estimator.predict(X)\n",
    "        \n",
    "        # Replace invalid values with 1\n",
    "        predictions = np.nan_to_num(predictions, nan=1, posinf=1, neginf=-1)\n",
    "        \n",
    "        # Ensure values are within valid range\n",
    "        predictions = np.clip(predictions, -1, 1)\n",
    "        \n",
    "        # Use safer conversion method\n",
    "        labels = np.where(predictions > 0, 0, 1)\n",
    "        \n",
    "        return f1_score(y, labels, average='weighted')\n",
    "    except Exception as e:\n",
    "        print(f\"Scoring error: {str(e)}\")\n",
    "        return 0.0\n",
    "\n",
    "# Initialize grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=IsolationForest(n_jobs=1, random_state=42),\n",
    "    param_grid=params,\n",
    "    scoring=custom_f1_scorer,\n",
    "    cv=3,                  # 3-fold cross-validation\n",
    "    n_jobs=4,             \n",
    "    verbose=1              \n",
    ")\n",
    "\n",
    "# Execute grid search\n",
    "print(\"Starting grid search...\")\n",
    "grid_search.fit(X_train_selected, y_train_split)\n",
    "\n",
    "# Get the best model\n",
    "best_iso_forest = grid_search.best_estimator_\n",
    "print(\"\\nBest parameters found:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"Best F1-score: {grid_search.best_score_:.3f}\")\n",
    "\n",
    "# Retrain with best parameters on full training set\n",
    "print(\"\\nRetraining with best parameters on full training set...\")\n",
    "final_model = grid_search.best_estimator_.fit(X_train_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on Training Set...\n",
      "\n",
      "Unsupervised Metrics (Training Set):\n",
      "Silhouette Score: 0.384\n",
      "Davies-Bouldin Index: 2.398\n",
      "\n",
      "Supervised Metrics (Training Set):\n",
      "Accuracy: 0.656\n",
      "Precision: 0.702\n",
      "Recall: 0.453\n",
      "F1-score: 0.550\n",
      "\n",
      "Confusion Matrix (Training Set):\n",
      "[[44868  9006]\n",
      " [25676 21228]]\n",
      "\n",
      "Evaluating on Validation Set...\n",
      "\n",
      "Unsupervised Metrics (Validation Set):\n",
      "Silhouette Score: 0.381\n",
      "Davies-Bouldin Index: 2.091\n",
      "\n",
      "Supervised Metrics (Validation Set):\n",
      "Accuracy: 0.662\n",
      "Precision: 0.710\n",
      "Recall: 0.462\n",
      "F1-score: 0.559\n",
      "\n",
      "Confusion Matrix (Validation Set):\n",
      "[[11253  2216]\n",
      " [ 6311  5415]]\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Evaluate on Training and Validation Sets\n",
    "# Training Set Evaluation\n",
    "print(\"\\nEvaluating on Training Set...\")\n",
    "train_predictions = best_iso_forest.predict(X_train_selected)\n",
    "train_scores = best_iso_forest.score_samples(X_train_selected)\n",
    "train_labels = (-train_predictions/2 + 0.5).astype(int)\n",
    "\n",
    "if len(np.unique(train_labels)) > 1:\n",
    "    train_silhouette = silhouette_score(X_train_selected, train_labels)\n",
    "    train_davies_bouldin = davies_bouldin_score(X_train_selected, train_labels)\n",
    "    print(\"\\nUnsupervised Metrics (Training Set):\")\n",
    "    print(f\"Silhouette Score: {train_silhouette:.3f}\")\n",
    "    print(f\"Davies-Bouldin Index: {train_davies_bouldin:.3f}\")\n",
    "\n",
    "train_accuracy = accuracy_score(y_train_split, train_labels)\n",
    "train_precision, train_recall, train_f1, _ = precision_recall_fscore_support(y_train_split, train_labels, average='binary')\n",
    "train_conf_matrix = confusion_matrix(y_train_split, train_labels)\n",
    "\n",
    "print(\"\\nSupervised Metrics (Training Set):\")\n",
    "print(f\"Accuracy: {train_accuracy:.3f}\")\n",
    "print(f\"Precision: {train_precision:.3f}\")\n",
    "print(f\"Recall: {train_recall:.3f}\")\n",
    "print(f\"F1-score: {train_f1:.3f}\")\n",
    "print(\"\\nConfusion Matrix (Training Set):\")\n",
    "print(train_conf_matrix)\n",
    "\n",
    "# Validation Set Evaluation\n",
    "print(\"\\nEvaluating on Validation Set...\")\n",
    "val_predictions = best_iso_forest.predict(X_val_selected)\n",
    "val_scores = best_iso_forest.score_samples(X_val_selected)\n",
    "val_labels = (-val_predictions/2 + 0.5).astype(int)\n",
    "\n",
    "if len(np.unique(val_labels)) > 1:\n",
    "    val_silhouette = silhouette_score(X_val_selected, val_labels)\n",
    "    val_davies_bouldin = davies_bouldin_score(X_val_selected, val_labels)\n",
    "    print(\"\\nUnsupervised Metrics (Validation Set):\")\n",
    "    print(f\"Silhouette Score: {val_silhouette:.3f}\")\n",
    "    print(f\"Davies-Bouldin Index: {val_davies_bouldin:.3f}\")\n",
    "\n",
    "val_accuracy = accuracy_score(y_val, val_labels)\n",
    "val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(y_val, val_labels, average='binary')\n",
    "val_conf_matrix = confusion_matrix(y_val, val_labels)\n",
    "\n",
    "print(\"\\nSupervised Metrics (Validation Set):\")\n",
    "print(f\"Accuracy: {val_accuracy:.3f}\")\n",
    "print(f\"Precision: {val_precision:.3f}\")\n",
    "print(f\"Recall: {val_recall:.3f}\")\n",
    "print(f\"F1-score: {val_f1:.3f}\")\n",
    "print(\"\\nConfusion Matrix (Validation Set):\")\n",
    "print(val_conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "Unsupervised Metrics (Test Set):\n",
      "Silhouette Score: -0.649\n",
      "Davies-Bouldin Index: 1.992\n",
      "\n",
      "Supervised Metrics (Test Set):\n",
      "Accuracy: 0.521\n",
      "Precision: 0.549\n",
      "Recall: 0.892\n",
      "F1-score: 0.680\n",
      "\n",
      "Confusion Matrix (Test Set):\n",
      "[[  307  9404]\n",
      " [ 1387 11446]]\n",
      "\n",
      "Sample Distribution Summary:\n",
      "\n",
      "Training Set:\n",
      "Normal: 70544, Anomaly: 30234\n",
      "\n",
      "Validation Set:\n",
      "Normal: 17564, Anomaly: 7631\n",
      "\n",
      "Test Set:\n",
      "Normal: 1694, Anomaly: 20850\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Evaluate on External Test Set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "# Load and preprocess test data\n",
    "df_test = pd.read_csv(processed_test_path)\n",
    "X_test_scaled = robust_scaler.transform(df_test)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# Load test labels\n",
    "y_test = pd.read_csv(test_labels_path)\n",
    "y_test_binary = y_test['label'].values\n",
    "\n",
    "# Get predictions\n",
    "test_predictions = best_iso_forest.predict(X_test_selected)\n",
    "test_scores = best_iso_forest.score_samples(X_test_selected)\n",
    "test_labels = (-test_predictions/2 + 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "if len(np.unique(test_labels)) > 1:\n",
    "    test_silhouette = silhouette_score(X_test_selected, test_labels)\n",
    "    test_davies_bouldin = davies_bouldin_score(X_test_selected, test_labels)\n",
    "    print(\"\\nUnsupervised Metrics (Test Set):\")\n",
    "    print(f\"Silhouette Score: {test_silhouette:.3f}\")\n",
    "    print(f\"Davies-Bouldin Index: {test_davies_bouldin:.3f}\")\n",
    "\n",
    "test_accuracy = accuracy_score(y_test_binary, test_labels)\n",
    "test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(y_test_binary, test_labels, average='binary')\n",
    "test_conf_matrix = confusion_matrix(y_test_binary, test_labels)\n",
    "\n",
    "print(\"\\nSupervised Metrics (Test Set):\")\n",
    "print(f\"Accuracy: {test_accuracy:.3f}\")\n",
    "print(f\"Precision: {test_precision:.3f}\")\n",
    "print(f\"Recall: {test_recall:.3f}\")\n",
    "print(f\"F1-score: {test_f1:.3f}\")\n",
    "print(\"\\nConfusion Matrix (Test Set):\")\n",
    "print(test_conf_matrix)\n",
    "\n",
    "# Print final distribution summary\n",
    "print(\"\\nSample Distribution Summary:\")\n",
    "print(\"\\nTraining Set:\")\n",
    "print(f\"Normal: {sum(train_labels == 0)}, Anomaly: {sum(train_labels == 1)}\")\n",
    "print(\"\\nValidation Set:\")\n",
    "print(f\"Normal: {sum(val_labels == 0)}, Anomaly: {sum(val_labels == 1)}\")\n",
    "print(\"\\nTest Set:\")\n",
    "print(f\"Normal: {sum(test_labels == 0)}, Anomaly: {sum(test_labels == 1)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sl-nsl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
