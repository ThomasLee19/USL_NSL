{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "train_dataset_path = '/root/autodl-tmp/projects/USL_NSL/dataset/transformed/KDDTrain+.csv'\n",
    "test_dataset_path = '/root/autodl-tmp/projects/USL_NSL/dataset/transformed/KDDTest+.csv'\n",
    "output_directory = '/root/autodl-tmp/projects/USL_NSL/dataset/processed/multi'\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mappings for multiclass classification:\n",
      "Class 0: Normal Traffic\n",
      "Class 1: DOS (Denial of Service)\n",
      "Class 2: Probe (Surveillance/Scanning)\n",
      "Class 3: R2L (Remote to Local)\n",
      "Class 4: U2R (User to Root)\n",
      "\n",
      "Detailed attack mappings:\n",
      "apache2: Class 1 (DOS (Denial of Service))\n",
      "back: Class 1 (DOS (Denial of Service))\n",
      "buffer_overflow: Class 4 (U2R (User to Root))\n",
      "ftp_write: Class 3 (R2L (Remote to Local))\n",
      "guess_passwd: Class 3 (R2L (Remote to Local))\n",
      "httptunnel: Class 3 (R2L (Remote to Local))\n",
      "imap: Class 3 (R2L (Remote to Local))\n",
      "ipsweep: Class 2 (Probe (Surveillance/Scanning))\n",
      "land: Class 1 (DOS (Denial of Service))\n",
      "loadmodule: Class 4 (U2R (User to Root))\n",
      "mailbomb: Class 1 (DOS (Denial of Service))\n",
      "mscan: Class 2 (Probe (Surveillance/Scanning))\n",
      "multihop: Class 3 (R2L (Remote to Local))\n",
      "named: Class 3 (R2L (Remote to Local))\n",
      "neptune: Class 1 (DOS (Denial of Service))\n",
      "nmap: Class 2 (Probe (Surveillance/Scanning))\n",
      "normal: Class 0 (Normal Traffic)\n",
      "perl: Class 4 (U2R (User to Root))\n",
      "phf: Class 3 (R2L (Remote to Local))\n",
      "pod: Class 1 (DOS (Denial of Service))\n",
      "portsweep: Class 2 (Probe (Surveillance/Scanning))\n",
      "processtable: Class 1 (DOS (Denial of Service))\n",
      "ps: Class 4 (U2R (User to Root))\n",
      "rootkit: Class 4 (U2R (User to Root))\n",
      "saint: Class 2 (Probe (Surveillance/Scanning))\n",
      "satan: Class 2 (Probe (Surveillance/Scanning))\n",
      "sendmail: Class 3 (R2L (Remote to Local))\n",
      "smurf: Class 1 (DOS (Denial of Service))\n",
      "snmpgetattack: Class 3 (R2L (Remote to Local))\n",
      "snmpguess: Class 3 (R2L (Remote to Local))\n",
      "spy: Class 3 (R2L (Remote to Local))\n",
      "sqlattack: Class 4 (U2R (User to Root))\n",
      "teardrop: Class 1 (DOS (Denial of Service))\n",
      "udpstorm: Class 1 (DOS (Denial of Service))\n",
      "warezclient: Class 3 (R2L (Remote to Local))\n",
      "warezmaster: Class 3 (R2L (Remote to Local))\n",
      "worm: Class 3 (R2L (Remote to Local))\n",
      "xlock: Class 3 (R2L (Remote to Local))\n",
      "xsnoop: Class 3 (R2L (Remote to Local))\n",
      "xterm: Class 4 (U2R (User to Root))\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Define attack mappings for multiclass classification\n",
    "attack_mapping = {\n",
    "    # Normal (0)\n",
    "    'normal': 0,\n",
    "    \n",
    "    # DOS attacks (1)\n",
    "    'back': 1,\n",
    "    'land': 1,\n",
    "    'neptune': 1,\n",
    "    'pod': 1,\n",
    "    'smurf': 1,\n",
    "    'teardrop': 1,\n",
    "    'apache2': 1,\n",
    "    'udpstorm': 1,\n",
    "    'processtable': 1,\n",
    "    'mailbomb': 1,\n",
    "    \n",
    "    # Probe attacks (2)\n",
    "    'ipsweep': 2,\n",
    "    'nmap': 2,\n",
    "    'portsweep': 2,\n",
    "    'satan': 2,\n",
    "    'mscan': 2,\n",
    "    'saint': 2,\n",
    "    \n",
    "    # R2L attacks (3)\n",
    "    'ftp_write': 3,\n",
    "    'guess_passwd': 3,\n",
    "    'imap': 3,\n",
    "    'multihop': 3,\n",
    "    'phf': 3,\n",
    "    'spy': 3,\n",
    "    'warezclient': 3,\n",
    "    'warezmaster': 3,\n",
    "    'snmpguess': 3,\n",
    "    'worm': 3,\n",
    "    'snmpgetattack': 3,\n",
    "    'httptunnel': 3,\n",
    "    'sendmail': 3,\n",
    "    'named': 3,\n",
    "    'xlock': 3,\n",
    "    'xsnoop': 3,\n",
    "    \n",
    "    # U2R attacks (4)\n",
    "    'buffer_overflow': 4,\n",
    "    'loadmodule': 4,\n",
    "    'perl': 4,\n",
    "    'rootkit': 4,\n",
    "    'sqlattack': 4,\n",
    "    'xterm': 4,\n",
    "    'ps': 4\n",
    "}\n",
    "\n",
    "# Define class names for better readability\n",
    "class_names = {\n",
    "    0: \"Normal Traffic\",\n",
    "    1: \"DOS (Denial of Service)\",\n",
    "    2: \"Probe (Surveillance/Scanning)\",\n",
    "    3: \"R2L (Remote to Local)\",\n",
    "    4: \"U2R (User to Root)\"\n",
    "}\n",
    "\n",
    "# Print class mappings\n",
    "print(\"Class mappings for multiclass classification:\")\n",
    "for class_id, class_name in class_names.items():\n",
    "    print(f\"Class {class_id}: {class_name}\")\n",
    "print(\"\\nDetailed attack mappings:\")\n",
    "for attack, class_id in sorted(attack_mapping.items()):\n",
    "    print(f\"{attack}: Class {class_id} ({class_names[class_id]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training dataset...\n",
      "Training dataset shape: (125973, 42)\n",
      "\n",
      "Sample of training data:\n",
      "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
      "0         0           tcp  ftp_data   SF        491          0     0   \n",
      "1         0           udp     other   SF        146          0     0   \n",
      "2         0           tcp   private   S0          0          0     0   \n",
      "3         0           tcp      http   SF        232       8153     0   \n",
      "4         0           tcp      http   SF        199        420     0   \n",
      "\n",
      "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
      "0               0       0    0  ...                  25   \n",
      "1               0       0    0  ...                   1   \n",
      "2               0       0    0  ...                  26   \n",
      "3               0       0    0  ...                 255   \n",
      "4               0       0    0  ...                 255   \n",
      "\n",
      "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
      "0                    0.17                    0.03   \n",
      "1                    0.00                    0.60   \n",
      "2                    0.10                    0.05   \n",
      "3                    1.00                    0.00   \n",
      "4                    1.00                    0.00   \n",
      "\n",
      "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
      "0                         0.17                         0.00   \n",
      "1                         0.88                         0.00   \n",
      "2                         0.00                         0.00   \n",
      "3                         0.03                         0.04   \n",
      "4                         0.00                         0.00   \n",
      "\n",
      "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
      "0                  0.00                      0.00                  0.05   \n",
      "1                  0.00                      0.00                  0.00   \n",
      "2                  1.00                      1.00                  0.00   \n",
      "3                  0.03                      0.01                  0.00   \n",
      "4                  0.00                      0.00                  0.00   \n",
      "\n",
      "   dst_host_srv_rerror_rate    label  \n",
      "0                      0.00   normal  \n",
      "1                      0.00   normal  \n",
      "2                      0.00  neptune  \n",
      "3                      0.01   normal  \n",
      "4                      0.00   normal  \n",
      "\n",
      "[5 rows x 42 columns]\n",
      "\n",
      "Data types:\n",
      "duration                         int64\n",
      "protocol_type                   object\n",
      "service                         object\n",
      "flag                            object\n",
      "src_bytes                        int64\n",
      "dst_bytes                        int64\n",
      "land                             int64\n",
      "wrong_fragment                   int64\n",
      "urgent                           int64\n",
      "hot                              int64\n",
      "num_failed_logins                int64\n",
      "logged_in                        int64\n",
      "num_compromised                  int64\n",
      "root_shell                       int64\n",
      "su_attempted                     int64\n",
      "num_root                         int64\n",
      "num_file_creations               int64\n",
      "num_shells                       int64\n",
      "num_access_files                 int64\n",
      "num_outbound_cmds                int64\n",
      "is_host_login                    int64\n",
      "is_guest_login                   int64\n",
      "count                            int64\n",
      "srv_count                        int64\n",
      "serror_rate                    float64\n",
      "srv_serror_rate                float64\n",
      "rerror_rate                    float64\n",
      "srv_rerror_rate                float64\n",
      "same_srv_rate                  float64\n",
      "diff_srv_rate                  float64\n",
      "srv_diff_host_rate             float64\n",
      "dst_host_count                   int64\n",
      "dst_host_srv_count               int64\n",
      "dst_host_same_srv_rate         float64\n",
      "dst_host_diff_srv_rate         float64\n",
      "dst_host_same_src_port_rate    float64\n",
      "dst_host_srv_diff_host_rate    float64\n",
      "dst_host_serror_rate           float64\n",
      "dst_host_srv_serror_rate       float64\n",
      "dst_host_rerror_rate           float64\n",
      "dst_host_srv_rerror_rate       float64\n",
      "label                           object\n",
      "dtype: object\n",
      "\n",
      "Original class distribution in training dataset:\n",
      "normal             67343\n",
      "neptune            41214\n",
      "satan               3633\n",
      "ipsweep             3599\n",
      "portsweep           2931\n",
      "smurf               2646\n",
      "nmap                1493\n",
      "back                 956\n",
      "teardrop             892\n",
      "warezclient          890\n",
      "pod                  201\n",
      "guess_passwd          53\n",
      "buffer_overflow       30\n",
      "warezmaster           20\n",
      "land                  18\n",
      "imap                  11\n",
      "rootkit               10\n",
      "loadmodule             9\n",
      "ftp_write              8\n",
      "multihop               7\n",
      "phf                    4\n",
      "perl                   3\n",
      "spy                    2\n",
      "Name: label, dtype: int64\n",
      "Percentage:\n",
      "normal             53.458281\n",
      "neptune            32.716534\n",
      "satan               2.883951\n",
      "ipsweep             2.856961\n",
      "portsweep           2.326689\n",
      "smurf               2.100450\n",
      "nmap                1.185175\n",
      "back                0.758893\n",
      "teardrop            0.708088\n",
      "warezclient         0.706501\n",
      "pod                 0.159558\n",
      "guess_passwd        0.042073\n",
      "buffer_overflow     0.023815\n",
      "warezmaster         0.015876\n",
      "land                0.014289\n",
      "imap                0.008732\n",
      "rootkit             0.007938\n",
      "loadmodule          0.007144\n",
      "ftp_write           0.006351\n",
      "multihop            0.005557\n",
      "phf                 0.003175\n",
      "perl                0.002381\n",
      "spy                 0.001588\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load and explore training dataset\n",
    "print(\"\\nLoading training dataset...\")\n",
    "df_train = pd.read_csv(train_dataset_path)\n",
    "\n",
    "# Display initial information\n",
    "print(\"Training dataset shape:\", df_train.shape)\n",
    "print(\"\\nSample of training data:\")\n",
    "print(df_train.head())\n",
    "print(\"\\nData types:\")\n",
    "print(df_train.dtypes)\n",
    "\n",
    "# Display original class distribution\n",
    "print(\"\\nOriginal class distribution in training dataset:\")\n",
    "print(df_train['label'].value_counts())\n",
    "print(\"Percentage:\")\n",
    "print(df_train['label'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying feature scaling...\n",
      "Sample of scaled training data:\n",
      "   duration protocol_type   service flag  src_bytes  dst_bytes      land  \\\n",
      "0 -0.110249           tcp  ftp_data   SF  -0.007679  -0.004919 -0.014089   \n",
      "1 -0.110249           udp     other   SF  -0.007737  -0.004919 -0.014089   \n",
      "2 -0.110249           tcp   private   S0  -0.007762  -0.004919 -0.014089   \n",
      "3 -0.110249           tcp      http   SF  -0.007723  -0.002891 -0.014089   \n",
      "4 -0.110249           tcp      http   SF  -0.007728  -0.004814 -0.014089   \n",
      "\n",
      "   wrong_fragment    urgent       hot  ...  dst_host_srv_count  \\\n",
      "0       -0.089486 -0.007736 -0.095076  ...           -0.818890   \n",
      "1       -0.089486 -0.007736 -0.095076  ...           -1.035688   \n",
      "2       -0.089486 -0.007736 -0.095076  ...           -0.809857   \n",
      "3       -0.089486 -0.007736 -0.095076  ...            1.258754   \n",
      "4       -0.089486 -0.007736 -0.095076  ...            1.258754   \n",
      "\n",
      "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
      "0               -0.782367               -0.280282   \n",
      "1               -1.161030                2.736852   \n",
      "2               -0.938287               -0.174417   \n",
      "3                1.066401               -0.439078   \n",
      "4                1.066401               -0.439078   \n",
      "\n",
      "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
      "0                     0.069972                    -0.289103   \n",
      "1                     2.367737                    -0.289103   \n",
      "2                    -0.480197                    -0.289103   \n",
      "3                    -0.383108                     0.066252   \n",
      "4                    -0.480197                    -0.289103   \n",
      "\n",
      "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
      "0             -0.639532                 -0.624871             -0.224532   \n",
      "1             -0.639532                 -0.624871             -0.387635   \n",
      "2              1.608759                  1.618955             -0.387635   \n",
      "3             -0.572083                 -0.602433             -0.387635   \n",
      "4             -0.639532                 -0.624871             -0.387635   \n",
      "\n",
      "   dst_host_srv_rerror_rate    label  \n",
      "0                 -0.376387   normal  \n",
      "1                 -0.376387   normal  \n",
      "2                 -0.376387  neptune  \n",
      "3                 -0.345084   normal  \n",
      "4                 -0.376387   normal  \n",
      "\n",
      "[5 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Feature scaling\n",
    "def feature_scaling(df, scaler=None):\n",
    "    \"\"\"\n",
    "    Scale numerical features using StandardScaler.\n",
    "    Returns scaled dataframe and scaler object.\n",
    "    \"\"\"\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "    # Get numeric columns (excluding the label column)\n",
    "    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    \n",
    "    # Fit and transform\n",
    "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "    \n",
    "    return df, scaler\n",
    "\n",
    "# Apply scaling to training data\n",
    "print(\"\\nApplying feature scaling...\")\n",
    "df_train, scaler = feature_scaling(df_train)\n",
    "print(\"Sample of scaled training data:\")\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying dummy transformation...\n",
      "Sample of data after dummy transformation:\n",
      "   duration  src_bytes  dst_bytes      land  wrong_fragment    urgent  \\\n",
      "0 -0.110249  -0.007679  -0.004919 -0.014089       -0.089486 -0.007736   \n",
      "1 -0.110249  -0.007737  -0.004919 -0.014089       -0.089486 -0.007736   \n",
      "2 -0.110249  -0.007762  -0.004919 -0.014089       -0.089486 -0.007736   \n",
      "3 -0.110249  -0.007723  -0.002891 -0.014089       -0.089486 -0.007736   \n",
      "4 -0.110249  -0.007728  -0.004814 -0.014089       -0.089486 -0.007736   \n",
      "\n",
      "        hot  num_failed_logins  logged_in  num_compromised  ...  flag_REJ  \\\n",
      "0 -0.095076          -0.027023  -0.809262        -0.011664  ...         0   \n",
      "1 -0.095076          -0.027023  -0.809262        -0.011664  ...         0   \n",
      "2 -0.095076          -0.027023  -0.809262        -0.011664  ...         0   \n",
      "3 -0.095076          -0.027023   1.235694        -0.011664  ...         0   \n",
      "4 -0.095076          -0.027023   1.235694        -0.011664  ...         0   \n",
      "\n",
      "   flag_RSTO  flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  \\\n",
      "0          0            0          0        0        0        0        0   \n",
      "1          0            0          0        0        0        0        0   \n",
      "2          0            0          0        1        0        0        0   \n",
      "3          0            0          0        0        0        0        0   \n",
      "4          0            0          0        0        0        0        0   \n",
      "\n",
      "   flag_SF  flag_SH  \n",
      "0        1        0  \n",
      "1        1        0  \n",
      "2        0        0  \n",
      "3        1        0  \n",
      "4        1        0  \n",
      "\n",
      "[5 rows x 123 columns]\n",
      "New shape after creating dummy variables: (125973, 123)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Categorical variables to dummy variables\n",
    "def get_dummies_transform(df, reference_df=None):\n",
    "    \"\"\"\n",
    "    Convert categorical variables to dummy/indicator variables.\n",
    "    If reference_df is provided, ensure the same dummy columns as in reference_df.\n",
    "    \"\"\"\n",
    "    categorical_columns = ['protocol_type', 'service', 'flag']\n",
    "    \n",
    "    # Create dummy variables\n",
    "    df_dummy = pd.get_dummies(df, columns=categorical_columns, dtype=int)\n",
    "    \n",
    "    if reference_df is not None:\n",
    "        # Add missing columns from reference_df\n",
    "        for col in reference_df.columns:\n",
    "            if col not in df_dummy.columns:\n",
    "                df_dummy[col] = 0\n",
    "        \n",
    "        # Ensure same column order as reference_df\n",
    "        df_dummy = df_dummy[reference_df.columns]\n",
    "    \n",
    "    return df_dummy\n",
    "\n",
    "# Apply get_dummies transformation\n",
    "print(\"\\nApplying dummy transformation...\")\n",
    "df_train = get_dummies_transform(df_train)\n",
    "print(\"Sample of data after dummy transformation:\")\n",
    "print(df_train.head())\n",
    "print(\"New shape after creating dummy variables:\", df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating multiclass labels...\n",
      "\n",
      "Multiclass distribution in training data:\n",
      "Class 0 (Normal Traffic): 67343 samples (53.46%)\n",
      "Class 1 (DOS (Denial of Service)): 45927 samples (36.46%)\n",
      "Class 2 (Probe (Surveillance/Scanning)): 11656 samples (9.25%)\n",
      "Class 3 (R2L (Remote to Local)): 995 samples (0.79%)\n",
      "Class 4 (U2R (User to Root)): 52 samples (0.04%)\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Create multiclass labels\n",
    "print(\"\\nCreating multiclass labels...\")\n",
    "df_train['multiclass_label'] = df_train['label'].map(attack_mapping)\n",
    "\n",
    "# Print class distribution\n",
    "print(\"\\nMulticlass distribution in training data:\")\n",
    "class_dist = df_train['multiclass_label'].value_counts().sort_index()\n",
    "for class_id, count in class_dist.items():\n",
    "    print(f\"Class {class_id} ({class_names[class_id]}): {count} samples ({count/len(df_train)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying unsupervised feature selection...\n",
      "Selected features: ['count', 'diff_srv_rate', 'dst_bytes', 'dst_host_count', 'dst_host_diff_srv_rate', 'dst_host_rerror_rate', 'dst_host_same_src_port_rate', 'dst_host_same_srv_rate', 'dst_host_serror_rate', 'dst_host_srv_count', 'dst_host_srv_diff_host_rate', 'dst_host_srv_rerror_rate', 'dst_host_srv_serror_rate', 'duration', 'flag_S0', 'flag_SF', 'hot', 'is_guest_login', 'is_host_login', 'land', 'logged_in', 'num_access_files', 'num_compromised', 'num_failed_logins', 'num_file_creations', 'num_root', 'num_shells', 'protocol_type_tcp', 'protocol_type_udp', 'rerror_rate', 'root_shell', 'same_srv_rate', 'serror_rate', 'service_http', 'service_private', 'src_bytes', 'srv_count', 'srv_diff_host_rate', 'srv_rerror_rate', 'srv_serror_rate', 'su_attempted', 'urgent', 'wrong_fragment']\n",
      "Shape after feature selection: (125973, 43)\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Feature selection using unsupervised method\n",
    "def unsupervised_feature_selection(df, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Perform feature selection using Variance Threshold.\n",
    "    Removes low-variance features that are less informative.\n",
    "    \"\"\"\n",
    "    selector = VarianceThreshold(threshold=threshold)\n",
    "    \n",
    "    # Exclude label columns\n",
    "    feature_cols = df.columns.difference(['label', 'multiclass_label'])\n",
    "    X_new = selector.fit_transform(df[feature_cols])\n",
    "    \n",
    "    selected_features = feature_cols[selector.get_support()].tolist()\n",
    "    \n",
    "    return X_new, selected_features, selector\n",
    "\n",
    "# Apply unsupervised feature selection\n",
    "print(\"\\nApplying unsupervised feature selection...\")\n",
    "X_train_selected, selected_features, selector = unsupervised_feature_selection(df_train)\n",
    "print(\"Selected features:\", selected_features)\n",
    "print(\"Shape after feature selection:\", X_train_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving processed data and preprocessing objects...\n",
      "\n",
      "Training set preprocessing complete!\n",
      "Processed training data saved to: /root/autodl-tmp/projects/USL_NSL/dataset/processed/multi/KDDTrain_processed.csv\n",
      "Training labels saved to: /root/autodl-tmp/projects/USL_NSL/dataset/processed/multi/KDDTrain_labels.csv\n",
      "Preprocessing objects saved to: /root/autodl-tmp/projects/USL_NSL/dataset/processed/multi/preprocessing_objects.pkl\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Create final training dataset and save\n",
    "# Create DataFrame with selected features and multiclass labels\n",
    "df_train_selected = pd.DataFrame(X_train_selected, columns=selected_features)\n",
    "df_train_selected['multiclass_label'] = df_train['multiclass_label'].values\n",
    "\n",
    "# Save processed data and preprocessing objects\n",
    "print(\"\\nSaving processed data and preprocessing objects...\")\n",
    "train_processed_path = os.path.join(output_directory, 'KDDTrain_processed.csv')\n",
    "df_train_selected.to_csv(train_processed_path, index=False)\n",
    "\n",
    "# Save original attack labels for reference\n",
    "train_labels_path = os.path.join(output_directory, 'KDDTrain_labels.csv')\n",
    "df_train[['label', 'multiclass_label']].to_csv(train_labels_path, index=False)\n",
    "\n",
    "# Save preprocessing objects\n",
    "preprocessing_objects = {\n",
    "    'scaler': scaler,\n",
    "    'selector': selector,\n",
    "    'selected_features': selected_features,\n",
    "    'attack_mapping': attack_mapping,\n",
    "    'class_names': class_names\n",
    "}\n",
    "\n",
    "encoders_path = os.path.join(output_directory, 'preprocessing_objects.pkl')\n",
    "with open(encoders_path, 'wb') as f:\n",
    "    pickle.dump(preprocessing_objects, f)\n",
    "\n",
    "print(\"\\nTraining set preprocessing complete!\")\n",
    "print(f\"Processed training data saved to: {train_processed_path}\")\n",
    "print(f\"Training labels saved to: {train_labels_path}\")\n",
    "print(f\"Preprocessing objects saved to: {encoders_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading testing dataset...\n",
      "Applying feature scaling...\n",
      "Applying dummy transformation...\n",
      "Creating multiclass labels...\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Process test dataset\n",
    "print(\"\\nLoading testing dataset...\")\n",
    "df_test = pd.read_csv(test_dataset_path)\n",
    "\n",
    "# Apply feature scaling using training scaler\n",
    "print(\"Applying feature scaling...\")\n",
    "df_test, _ = feature_scaling(df_test, scaler=scaler)\n",
    "\n",
    "# Apply get_dummies transformation using training data as reference\n",
    "print(\"Applying dummy transformation...\")\n",
    "df_test = get_dummies_transform(df_test, reference_df=df_train)\n",
    "\n",
    "# Create multiclass labels for test set\n",
    "print(\"Creating multiclass labels...\")\n",
    "df_test['multiclass_label'] = df_test['label'].map(attack_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multiclass distribution in test data:\n",
      "Class 0 (Normal Traffic): 9711 samples (43.08%)\n",
      "Class 1 (DOS (Denial of Service)): 7458 samples (33.08%)\n",
      "Class 2 (Probe (Surveillance/Scanning)): 2421 samples (10.74%)\n",
      "Class 3 (R2L (Remote to Local)): 2887 samples (12.81%)\n",
      "Class 4 (U2R (User to Root)): 67 samples (0.30%)\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Handle unknown attacks in test data\n",
    "unknown_attacks = df_test[df_test['multiclass_label'].isna()]['label'].unique()\n",
    "if len(unknown_attacks) > 0:\n",
    "    print(f\"Warning: Found {len(unknown_attacks)} unknown attack types in test data:\")\n",
    "    print(unknown_attacks)\n",
    "    \n",
    "    # Assign most similar category based on naming convention\n",
    "    # This is a simple heuristic and might need domain expertise refinement\n",
    "    for attack in unknown_attacks:\n",
    "        if any(dos in attack.lower() for dos in ['dos', 'flood', 'storm', 'smurf']):\n",
    "            df_test.loc[df_test['label'] == attack, 'multiclass_label'] = 1  # DOS\n",
    "        elif any(probe in attack.lower() for probe in ['scan', 'sweep', 'probe']):\n",
    "            df_test.loc[df_test['label'] == attack, 'multiclass_label'] = 2  # Probe\n",
    "        elif any(r2l in attack.lower() for r2l in ['ftp', 'guess', 'imap', 'pass', 'http']):\n",
    "            df_test.loc[df_test['label'] == attack, 'multiclass_label'] = 3  # R2L\n",
    "        elif any(u2r in attack.lower() for u2r in ['root', 'overflow', 'perl', 'sql']):\n",
    "            df_test.loc[df_test['label'] == attack, 'multiclass_label'] = 4  # U2R\n",
    "        else:\n",
    "            # Default to most common attack class in training data (after normal)\n",
    "            most_common_attack_class = df_train[df_train['multiclass_label'] != 0]['multiclass_label'].mode()[0]\n",
    "            df_test.loc[df_test['label'] == attack, 'multiclass_label'] = most_common_attack_class\n",
    "            print(f\"  Assigned {attack} to class {most_common_attack_class} ({class_names[most_common_attack_class]}) by default\")\n",
    "\n",
    "# Print test set class distribution\n",
    "print(\"\\nMulticlass distribution in test data:\")\n",
    "test_dist = df_test['multiclass_label'].value_counts().sort_index()\n",
    "for class_id, count in test_dist.items():\n",
    "    print(f\"Class {class_id} ({class_names[class_id]}): {count} samples ({count/len(df_test)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying feature selection to test data...\n",
      "\n",
      "Test set preprocessing complete!\n",
      "Processed test data saved to: /root/autodl-tmp/projects/USL_NSL/dataset/processed/multi/KDDTest_processed.csv\n",
      "Test labels saved to: /root/autodl-tmp/projects/USL_NSL/dataset/processed/multi/KDDTest_labels.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Create final test dataset and save\n",
    "# Extract features using the same selector from training\n",
    "print(\"\\nApplying feature selection to test data...\")\n",
    "df_test_selected = pd.DataFrame(\n",
    "    df_test[selected_features].values,\n",
    "    columns=selected_features\n",
    ")\n",
    "df_test_selected['multiclass_label'] = df_test['multiclass_label'].values\n",
    "\n",
    "# Save processed test dataset\n",
    "test_processed_path = os.path.join(output_directory, 'KDDTest_processed.csv')\n",
    "df_test_selected.to_csv(test_processed_path, index=False)\n",
    "\n",
    "# Save original attack labels for reference\n",
    "test_labels_path = os.path.join(output_directory, 'KDDTest_labels.csv')\n",
    "df_test[['label', 'multiclass_label']].to_csv(test_labels_path, index=False)\n",
    "\n",
    "print(\"\\nTest set preprocessing complete!\")\n",
    "print(f\"Processed test data saved to: {test_processed_path}\")\n",
    "print(f\"Test labels saved to: {test_labels_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final dataset shapes:\n",
      "Training set: (125973, 44)\n",
      "Testing set: (22544, 44)\n",
      "\n",
      "Multiclass distribution in training dataset:\n",
      "Class 0 (Normal Traffic): 67343 samples (53.46%)\n",
      "Class 1 (DOS (Denial of Service)): 45927 samples (36.46%)\n",
      "Class 2 (Probe (Surveillance/Scanning)): 11656 samples (9.25%)\n",
      "Class 3 (R2L (Remote to Local)): 995 samples (0.79%)\n",
      "Class 4 (U2R (User to Root)): 52 samples (0.04%)\n",
      "\n",
      "Multiclass distribution in test dataset:\n",
      "Class 0 (Normal Traffic): 9711 samples (43.08%)\n",
      "Class 1 (DOS (Denial of Service)): 7458 samples (33.08%)\n",
      "Class 2 (Probe (Surveillance/Scanning)): 2421 samples (10.74%)\n",
      "Class 3 (R2L (Remote to Local)): 2887 samples (12.81%)\n",
      "Class 4 (U2R (User to Root)): 67 samples (0.30%)\n",
      "\n",
      "Class imbalance ratio (max/min) in training set: 1295.06\n",
      "Class imbalance ratio (max/min) in test set: 144.94\n",
      "\n",
      "Summary statistics for a few key features by class in the training set:\n",
      "\n",
      "Feature: count\n",
      "  Class 0 (Normal Traffic): mean=-0.5379, std=0.4718\n",
      "  Class 1 (DOS (Denial of Service)): mean=0.8207, std=0.9121\n",
      "  Class 2 (Probe (Surveillance/Scanning)): mean=-0.0616, std=1.3665\n",
      "  Class 3 (R2L (Remote to Local)): mean=-0.7232, std=0.0042\n",
      "  Class 4 (U2R (User to Root)): mean=-0.6838, std=0.2048\n",
      "\n",
      "Feature: diff_srv_rate\n",
      "  Class 0 (Normal Traffic): mean=-0.1900, std=0.8076\n",
      "  Class 1 (DOS (Denial of Service)): mean=0.0130, std=0.3551\n",
      "  Class 2 (Probe (Surveillance/Scanning)): mean=1.0732, std=2.2694\n",
      "  Class 3 (R2L (Remote to Local)): mean=-0.3125, std=0.4452\n",
      "  Class 4 (U2R (User to Root)): mean=0.0033, std=1.2274\n",
      "\n",
      "Feature: dst_bytes\n",
      "  Class 0 (Normal Traffic): mean=-0.0038, std=0.0163\n",
      "  Class 1 (DOS (Denial of Service)): mean=-0.0049, std=0.0003\n",
      "  Class 2 (Probe (Surveillance/Scanning)): mean=0.0401, std=3.2868\n",
      "  Class 3 (R2L (Remote to Local)): mean=0.0154, std=0.1566\n",
      "  Class 4 (U2R (User to Root)): mean=-0.0036, std=0.0025\n",
      "\n",
      "Feature: dst_host_count\n",
      "  Class 0 (Normal Traffic): mean=-0.3499, std=1.0260\n",
      "  Class 1 (DOS (Denial of Service)): mean=0.6295, std=0.4166\n",
      "  Class 2 (Probe (Surveillance/Scanning)): mean=-0.3724, std=1.1994\n",
      "  Class 3 (R2L (Remote to Local)): mean=-0.9386, std=1.1277\n",
      "  Class 4 (U2R (User to Root)): mean=-1.3546, std=0.9696\n",
      "\n",
      "Feature: dst_host_diff_srv_rate\n",
      "  Class 0 (Normal Traffic): mean=-0.2266, std=0.6803\n",
      "  Class 1 (DOS (Denial of Service)): mean=-0.0880, std=0.3074\n",
      "  Class 2 (Probe (Surveillance/Scanning)): mean=1.6849, std=2.1383\n",
      "  Class 3 (R2L (Remote to Local)): mean=-0.3263, std=0.3608\n",
      "  Class 4 (U2R (User to Root)): mean=-0.2273, std=0.7760\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Generate summary statistics and analysis\n",
    "# Display final shapes\n",
    "print(\"\\nFinal dataset shapes:\")\n",
    "print(f\"Training set: {df_train_selected.shape}\")\n",
    "print(f\"Testing set: {df_test_selected.shape}\")\n",
    "\n",
    "# Display class distributions\n",
    "print(\"\\nMulticlass distribution in training dataset:\")\n",
    "train_class_dist = df_train_selected['multiclass_label'].value_counts().sort_index()\n",
    "for class_id, count in train_class_dist.items():\n",
    "    print(f\"Class {class_id} ({class_names[class_id]}): {count} samples ({count/len(df_train_selected)*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nMulticlass distribution in test dataset:\")\n",
    "test_class_dist = df_test_selected['multiclass_label'].value_counts().sort_index()\n",
    "for class_id, count in test_class_dist.items():\n",
    "    print(f\"Class {class_id} ({class_names[class_id]}): {count} samples ({count/len(df_test_selected)*100:.2f}%)\")\n",
    "\n",
    "# Compute imbalance ratios\n",
    "train_ratio = train_class_dist.max() / train_class_dist.min()\n",
    "test_ratio = test_class_dist.max() / test_class_dist.min()\n",
    "print(f\"\\nClass imbalance ratio (max/min) in training set: {train_ratio:.2f}\")\n",
    "print(f\"Class imbalance ratio (max/min) in test set: {test_ratio:.2f}\")\n",
    "\n",
    "# Summary statistics of key features by class\n",
    "print(\"\\nSummary statistics for a few key features by class in the training set:\")\n",
    "key_features = selected_features[:5]  # Select a few important features\n",
    "for feature in key_features:\n",
    "    print(f\"\\nFeature: {feature}\")\n",
    "    for class_id in range(5):\n",
    "        class_values = df_train_selected[df_train_selected['multiclass_label'] == class_id][feature]\n",
    "        print(f\"  Class {class_id} ({class_names[class_id]}): mean={class_values.mean():.4f}, std={class_values.std():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sl-nsl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
