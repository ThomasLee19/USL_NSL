{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries and Setup Paths\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import OneClassSVM, SVC\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# Define paths\n",
    "processed_train_path = '/root/autodl-tmp/projects/USL_NSL/dataset/processed/multi/KDDTrain_processed.csv'\n",
    "processed_test_path = '/root/autodl-tmp/projects/USL_NSL/dataset/processed/multi/KDDTest_processed.csv'\n",
    "train_labels_path = '/root/autodl-tmp/projects/USL_NSL/dataset/processed/multi/KDDTrain_labels.csv'\n",
    "test_labels_path = '/root/autodl-tmp/projects/USL_NSL/dataset/processed/multi/KDDTest_labels.csv'\n",
    "\n",
    "# Load class names mapping\n",
    "preprocessing_path = '/root/autodl-tmp/projects/USL_NSL/dataset/processed/multi/preprocessing_objects.pkl'\n",
    "with open(preprocessing_path, 'rb') as f:\n",
    "    preprocessing_objects = pickle.load(f)\n",
    "    class_names = preprocessing_objects['class_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "\n",
      "Class distribution in training data:\n",
      "Class 0 (Normal Traffic): 67343 samples (53.46%)\n",
      "Class 1 (DOS (Denial of Service)): 45927 samples (36.46%)\n",
      "Class 2 (Probe (Surveillance/Scanning)): 11656 samples (9.25%)\n",
      "Class 3 (R2L (Remote to Local)): 995 samples (0.79%)\n",
      "Class 4 (U2R (User to Root)): 52 samples (0.04%)\n",
      "\n",
      "Dataset shapes:\n",
      "Training set: (100778, 43)\n",
      "Validation set: (25195, 43)\n",
      "Loading complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load and Prepare Data\n",
    "print(\"Loading training data...\")\n",
    "df_train = pd.read_csv(processed_train_path)\n",
    "X = df_train.drop('multiclass_label', axis=1).values\n",
    "y = df_train['multiclass_label'].values\n",
    "\n",
    "# Create binary labels (0: normal, 1: attack)\n",
    "y_binary = np.where(y == 0, 0, 1)\n",
    "\n",
    "# Split training set and validation set (80-20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "_, _, y_binary_train, y_binary_val = train_test_split(\n",
    "    X, y_binary, test_size=0.2, random_state=42, stratify=y_binary\n",
    ")\n",
    "\n",
    "# Display number of samples for each class\n",
    "class_dist = pd.Series(y).value_counts().sort_index()\n",
    "print(\"\\nClass distribution in training data:\")\n",
    "for class_id, count in class_dist.items():\n",
    "    print(f\"Class {class_id} ({class_names[class_id]}): {count} samples ({count/len(y)*100:.2f}%)\")\n",
    "\n",
    "# Display data information\n",
    "print(\"\\nDataset shapes:\")\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(\"Loading complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training OneClassSVM for anomaly detection (unsupervised learning)...\n",
      "Using 53874 normal samples for OneClassSVM training\n",
      "Applying SMOTE to handle class imbalance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/sl-nsl-env/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneClassSVM training completed in 65.60 seconds\n",
      "\n",
      "Unsupervised Evaluation Metrics:\n",
      "Silhouette Score: 0.011\n",
      "Davies-Bouldin Index: 1.459\n",
      "\n",
      "Prediction distribution (Training Set):\n",
      "{0: 23144, 1: 77634}\n",
      "\n",
      "Anomaly detector - Training set performance:\n",
      "Accuracy: 0.4813\n",
      "Precision: 0.4654\n",
      "Recall: 0.7703\n",
      "F1-score: 0.5802\n",
      "\n",
      "Anomaly detector - Validation set performance:\n",
      "Accuracy: 0.4781\n",
      "Precision: 0.4633\n",
      "Recall: 0.7662\n",
      "F1-score: 0.5774\n",
      "\n",
      "Confusion Matrix (Validation Set) - Binary Classification:\n",
      "True Negatives: 3061 | False Positives: 10408\n",
      "False Negatives: 2742 | True Positives: 8984\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Train OneClassSVM for Anomaly Detection (Unsupervised Learning)\n",
    "print(\"\\nTraining OneClassSVM for anomaly detection (unsupervised learning)...\")\n",
    "\n",
    "# Extract only normal traffic samples for training\n",
    "normal_indices = np.where(y_train == 0)[0]\n",
    "X_normal_train = X_train[normal_indices]\n",
    "print(f\"Using {len(X_normal_train)} normal samples for OneClassSVM training\")\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_normal_train_scaled = scaler.fit_transform(X_normal_train)\n",
    "\n",
    "# Handle class imbalance using SMOTE for binary classification\n",
    "print(\"Applying SMOTE to handle class imbalance...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_resampled, y_binary_resampled = smote.fit_resample(X_train_scaled, y_binary_train)\n",
    "\n",
    "# Train OneClassSVM with optimized parameters\n",
    "start_time = time.time()\n",
    "anomaly_detector = OneClassSVM(\n",
    "    kernel='rbf',\n",
    "    nu=0.35,           # Increased nu to improve recall\n",
    "    gamma='scale',     # Kernel coefficient\n",
    "    cache_size=1000,   # Increased cache size\n",
    "    max_iter=1000,     # Increased max iterations\n",
    "    tol=1e-4           # Set a smaller tolerance for convergence\n",
    ")\n",
    "\n",
    "anomaly_detector.fit(X_normal_train_scaled)\n",
    "anomaly_train_time = time.time() - start_time\n",
    "print(f\"OneClassSVM training completed in {anomaly_train_time:.2f} seconds\")\n",
    "\n",
    "# Function to convert OneClassSVM predictions to binary labels\n",
    "def convert_predictions(predictions):\n",
    "    return np.where(predictions == 1, 0, 1)\n",
    "\n",
    "# Evaluate anomaly detector on training set\n",
    "anomaly_train_pred_raw = anomaly_detector.predict(X_train_scaled)\n",
    "anomaly_train_pred = convert_predictions(anomaly_train_pred_raw)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "anomaly_train_accuracy = accuracy_score(y_binary_train, anomaly_train_pred)\n",
    "anomaly_train_precision, anomaly_train_recall, anomaly_train_f1, _ = precision_recall_fscore_support(\n",
    "    y_binary_train, anomaly_train_pred, average='binary'\n",
    ")\n",
    "\n",
    "# Calculate unsupervised evaluation metrics\n",
    "try:\n",
    "    silhouette_avg = silhouette_score(X_train_scaled, anomaly_train_pred)\n",
    "    davies_bouldin_idx = davies_bouldin_score(X_train_scaled, anomaly_train_pred)\n",
    "    print(\"\\nUnsupervised Evaluation Metrics:\")\n",
    "    print(f\"Silhouette Score: {silhouette_avg:.3f}\")\n",
    "    print(f\"Davies-Bouldin Index: {davies_bouldin_idx:.3f}\")\n",
    "except:\n",
    "    print(\"Could not calculate unsupervised metrics due to single class prediction\")\n",
    "\n",
    "# Print prediction distribution\n",
    "print(\"\\nPrediction distribution (Training Set):\")\n",
    "unique, counts = np.unique(anomaly_train_pred, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "print(f\"\\nAnomaly detector - Training set performance:\")\n",
    "print(f\"Accuracy: {anomaly_train_accuracy:.4f}\")\n",
    "print(f\"Precision: {anomaly_train_precision:.4f}\")\n",
    "print(f\"Recall: {anomaly_train_recall:.4f}\")\n",
    "print(f\"F1-score: {anomaly_train_f1:.4f}\")\n",
    "\n",
    "# Evaluate anomaly detector on validation set\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "anomaly_val_pred_raw = anomaly_detector.predict(X_val_scaled)\n",
    "anomaly_val_pred = convert_predictions(anomaly_val_pred_raw)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "anomaly_val_accuracy = accuracy_score(y_binary_val, anomaly_val_pred)\n",
    "anomaly_val_precision, anomaly_val_recall, anomaly_val_f1, _ = precision_recall_fscore_support(\n",
    "    y_binary_val, anomaly_val_pred, average='binary'\n",
    ")\n",
    "\n",
    "print(f\"\\nAnomaly detector - Validation set performance:\")\n",
    "print(f\"Accuracy: {anomaly_val_accuracy:.4f}\")\n",
    "print(f\"Precision: {anomaly_val_precision:.4f}\")\n",
    "print(f\"Recall: {anomaly_val_recall:.4f}\")\n",
    "print(f\"F1-score: {anomaly_val_f1:.4f}\")\n",
    "\n",
    "# Display confusion matrix for binary classification\n",
    "anomaly_val_cm = confusion_matrix(y_binary_val, anomaly_val_pred)\n",
    "print(\"\\nConfusion Matrix (Validation Set) - Binary Classification:\")\n",
    "print(f\"True Negatives: {anomaly_val_cm[0, 0]} | False Positives: {anomaly_val_cm[0, 1]}\")\n",
    "print(f\"False Negatives: {anomaly_val_cm[1, 0]} | True Positives: {anomaly_val_cm[1, 1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SVC for attack type classification (supervised learning)...\n",
      "\n",
      "Attack multiclass class weights:\n",
      "Attack Class 0 (Original 1, DOS (Denial of Service)): 0.3192\n",
      "Attack Class 1 (Original 2, Probe (Surveillance/Scanning)): 1.2575\n",
      "Attack Class 2 (Original 3, R2L (Remote to Local)): 14.7312\n",
      "Attack Class 3 (Original 4, U2R (User to Root)): 279.1905\n",
      "Attack classifier training completed in 107.39 seconds\n",
      "\n",
      "Attack classifier - Training set performance (attack samples only):\n",
      "Accuracy: 0.9935\n",
      "Macro-average precision: 0.8358\n",
      "Macro-average recall: 0.9711\n",
      "Macro-average F1-score: 0.8750\n",
      "\n",
      "Classification Report (Training Set) - Attack Types:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     36741\n",
      "           1       0.98      0.99      0.99      9325\n",
      "           2       0.98      0.97      0.98       796\n",
      "           3       0.38      0.93      0.54        42\n",
      "\n",
      "    accuracy                           0.99     46904\n",
      "   macro avg       0.84      0.97      0.87     46904\n",
      "weighted avg       0.99      0.99      0.99     46904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Train SVC for Attack Type Classification (Supervised Learning)\n",
    "print(\"\\nTraining SVC for attack type classification (supervised learning)...\")\n",
    "\n",
    "# Calculate class weights for attack types\n",
    "attack_indices_train = np.where(y_train != 0)[0]\n",
    "X_attack_train = X_train[attack_indices_train]\n",
    "y_attack_train = y_train[attack_indices_train]\n",
    "# Shift labels to start from 0 (1->0, 2->1, 3->2, 4->3)\n",
    "y_attack_train_shifted = y_attack_train - 1\n",
    "\n",
    "# Calculate class weights for attack types\n",
    "attack_class_weights = {}\n",
    "n_attack_samples = len(y_attack_train_shifted)\n",
    "n_attack_classes = len(np.unique(y_attack_train_shifted))\n",
    "for i in range(n_attack_classes):\n",
    "    n_class = np.sum(y_attack_train_shifted == i)\n",
    "    attack_class_weights[i] = n_attack_samples / (n_attack_classes * n_class)\n",
    "\n",
    "print(f\"\\nAttack multiclass class weights:\")\n",
    "for i in range(n_attack_classes):\n",
    "    print(f\"Attack Class {i} (Original {i+1}, {class_names[i+1]}): {attack_class_weights[i]:.4f}\")\n",
    "\n",
    "# Scale the attack data\n",
    "X_attack_train_scaled = scaler.transform(X_attack_train)\n",
    "\n",
    "# Train SVC for attack type classification\n",
    "start_time = time.time()\n",
    "attack_classifier = SVC(\n",
    "    kernel='rbf',\n",
    "    C=10,\n",
    "    gamma='scale',\n",
    "    class_weight=attack_class_weights,\n",
    "    probability=True\n",
    ")\n",
    "\n",
    "attack_classifier.fit(X_attack_train_scaled, y_attack_train_shifted)\n",
    "attack_train_time = time.time() - start_time\n",
    "print(f\"Attack classifier training completed in {attack_train_time:.2f} seconds\")\n",
    "\n",
    "# Evaluate attack classifier on attack samples from training set\n",
    "y_attack_train_pred = attack_classifier.predict(X_attack_train_scaled)\n",
    "attack_train_accuracy = accuracy_score(y_attack_train_shifted, y_attack_train_pred)\n",
    "attack_train_precision, attack_train_recall, attack_train_f1, _ = precision_recall_fscore_support(\n",
    "    y_attack_train_shifted, y_attack_train_pred, average='macro'\n",
    ")\n",
    "\n",
    "print(f\"\\nAttack classifier - Training set performance (attack samples only):\")\n",
    "print(f\"Accuracy: {attack_train_accuracy:.4f}\")\n",
    "print(f\"Macro-average precision: {attack_train_precision:.4f}\")\n",
    "print(f\"Macro-average recall: {attack_train_recall:.4f}\")\n",
    "print(f\"Macro-average F1-score: {attack_train_f1:.4f}\")\n",
    "\n",
    "# Display classification report for attack types\n",
    "attack_train_report = classification_report(y_attack_train_shifted, y_attack_train_pred)\n",
    "print(\"\\nClassification Report (Training Set) - Attack Types:\")\n",
    "print(attack_train_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating hybrid model on validation set...\n",
      "\n",
      "Hybrid model - Validation set performance:\n",
      "Accuracy: 0.6882\n",
      "Macro-average precision: 0.4950\n",
      "Macro-average recall: 0.8542\n",
      "Macro-average F1-score: 0.4815\n",
      "\n",
      "Classification Report (Validation Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.43      0.60     13469\n",
      "           1       0.71      0.99      0.83      9186\n",
      "           2       0.67      0.99      0.80      2331\n",
      "           3       0.09      0.96      0.16       199\n",
      "           4       0.01      0.90      0.02        10\n",
      "\n",
      "    accuracy                           0.69     25195\n",
      "   macro avg       0.50      0.85      0.48     25195\n",
      "weighted avg       0.85      0.69      0.70     25195\n",
      "\n",
      "\n",
      "Confusion Matrix (Validation Set):\n",
      "[[5758 3683 1047 1946 1035]\n",
      " [  45 9069   72    0    0]\n",
      " [   0    2 2311    2   16]\n",
      " [   0    0    0  192    7]\n",
      " [   0    0    0    1    9]]\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Evaluate Hybrid Model on Validation Set\n",
    "print(\"\\nEvaluating hybrid model on validation set...\")\n",
    "\n",
    "# Step 1: Use OneClassSVM to detect anomalies\n",
    "anomaly_val_pred = convert_predictions(anomaly_detector.predict(X_val_scaled))\n",
    "\n",
    "# Step 2: For samples classified as anomalies, predict the attack type\n",
    "anomaly_indices_val = np.where(anomaly_val_pred == 1)[0]\n",
    "X_anomaly_val = X_val_scaled[anomaly_indices_val]\n",
    "\n",
    "if len(anomaly_indices_val) > 0:\n",
    "    y_attack_val_pred = attack_classifier.predict(X_anomaly_val)\n",
    "    # Shift back to original labels (0->1, 1->2, 2->3, 3->4)\n",
    "    y_attack_val_pred_shifted = y_attack_val_pred + 1\n",
    "    \n",
    "    # Create final predictions\n",
    "    y_val_pred = np.zeros_like(y_val)\n",
    "    y_val_pred[anomaly_indices_val] = y_attack_val_pred_shifted\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(y_val, y_val_pred, average='macro')\n",
    "    val_report = classification_report(y_val, y_val_pred)\n",
    "    val_confusion = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"\\nHybrid model - Validation set performance:\")\n",
    "    print(f\"Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"Macro-average precision: {val_precision:.4f}\")\n",
    "    print(f\"Macro-average recall: {val_recall:.4f}\")\n",
    "    print(f\"Macro-average F1-score: {val_f1:.4f}\")\n",
    "    print(\"\\nClassification Report (Validation Set):\")\n",
    "    print(val_report)\n",
    "    print(\"\\nConfusion Matrix (Validation Set):\")\n",
    "    print(val_confusion)\n",
    "else:\n",
    "    print(\"No anomalies detected in validation set by OneClassSVM.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating hybrid model on test set...\n",
      "\n",
      "Class distribution in test data:\n",
      "Class 0 (Normal Traffic): 9711 samples (43.08%)\n",
      "Class 1 (DOS (Denial of Service)): 7458 samples (33.08%)\n",
      "Class 2 (Probe (Surveillance/Scanning)): 2421 samples (10.74%)\n",
      "Class 3 (R2L (Remote to Local)): 2887 samples (12.81%)\n",
      "Class 4 (U2R (User to Root)): 67 samples (0.30%)\n",
      "\n",
      "Anomaly detector - Test set performance:\n",
      "Accuracy: 0.5692\n",
      "Precision: 0.5692\n",
      "Recall: 1.0000\n",
      "F1-score: 0.7255\n",
      "\n",
      "Confusion Matrix (Test Set) - Binary Classification:\n",
      "True Negatives: 0 | False Positives: 9711\n",
      "False Negatives: 0 | True Positives: 12833\n",
      "\n",
      "Hybrid model - Test set performance:\n",
      "Accuracy: 0.4275\n",
      "Macro-average precision: 0.2681\n",
      "Macro-average recall: 0.5070\n",
      "Macro-average F1-score: 0.3345\n",
      "\n",
      "Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      9711\n",
      "           1       0.46      0.84      0.59      7458\n",
      "           2       0.53      0.88      0.66      2421\n",
      "           3       0.33      0.43      0.37      2887\n",
      "           4       0.02      0.39      0.05        67\n",
      "\n",
      "    accuracy                           0.43     22544\n",
      "   macro avg       0.27      0.51      0.33     22544\n",
      "weighted avg       0.25      0.43      0.31     22544\n",
      "\n",
      "\n",
      "Confusion Matrix (Test Set):\n",
      "[[   0 6734  759 1693  525]\n",
      " [   0 6236  320  845   57]\n",
      " [   0  284 2128    1    8]\n",
      " [   0  437  774 1247  429]\n",
      " [   0    2    4   35   26]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/sl-nsl-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/root/miniconda3/envs/sl-nsl-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/root/miniconda3/envs/sl-nsl-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/root/miniconda3/envs/sl-nsl-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Evaluate Hybrid Model on Test Set\n",
    "print(\"\\nEvaluating hybrid model on test set...\")\n",
    "\n",
    "# Load test data\n",
    "df_test = pd.read_csv(processed_test_path)\n",
    "X_test = df_test.drop('multiclass_label', axis=1).values\n",
    "y_test = df_test['multiclass_label'].values\n",
    "y_binary_test = np.where(y_test == 0, 0, 1)\n",
    "\n",
    "# Display distribution of classes in test data\n",
    "test_class_dist = pd.Series(y_test).value_counts().sort_index()\n",
    "print(\"\\nClass distribution in test data:\")\n",
    "for class_id, count in test_class_dist.items():\n",
    "    print(f\"Class {class_id} ({class_names[class_id]}): {count} samples ({count/len(y_test)*100:.2f}%)\")\n",
    "\n",
    "# Scale test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 1: Use OneClassSVM to detect anomalies\n",
    "anomaly_test_pred_raw = anomaly_detector.predict(X_test_scaled)\n",
    "anomaly_test_pred = convert_predictions(anomaly_test_pred_raw)\n",
    "\n",
    "# Calculate binary classification metrics\n",
    "anomaly_test_accuracy = accuracy_score(y_binary_test, anomaly_test_pred)\n",
    "anomaly_test_precision, anomaly_test_recall, anomaly_test_f1, _ = precision_recall_fscore_support(\n",
    "    y_binary_test, anomaly_test_pred, average='binary'\n",
    ")\n",
    "\n",
    "print(f\"\\nAnomaly detector - Test set performance:\")\n",
    "print(f\"Accuracy: {anomaly_test_accuracy:.4f}\")\n",
    "print(f\"Precision: {anomaly_test_precision:.4f}\")\n",
    "print(f\"Recall: {anomaly_test_recall:.4f}\")\n",
    "print(f\"F1-score: {anomaly_test_f1:.4f}\")\n",
    "\n",
    "# Display confusion matrix for binary classification\n",
    "anomaly_test_cm = confusion_matrix(y_binary_test, anomaly_test_pred)\n",
    "print(\"\\nConfusion Matrix (Test Set) - Binary Classification:\")\n",
    "print(f\"True Negatives: {anomaly_test_cm[0, 0]} | False Positives: {anomaly_test_cm[0, 1]}\")\n",
    "print(f\"False Negatives: {anomaly_test_cm[1, 0]} | True Positives: {anomaly_test_cm[1, 1]}\")\n",
    "\n",
    "# Step 2: For samples classified as anomalies, predict the attack type\n",
    "anomaly_indices_test = np.where(anomaly_test_pred == 1)[0]\n",
    "X_anomaly_test = X_test_scaled[anomaly_indices_test]\n",
    "\n",
    "if len(anomaly_indices_test) > 0:\n",
    "    y_attack_test_pred = attack_classifier.predict(X_anomaly_test)\n",
    "    # Shift back to original labels\n",
    "    y_attack_test_pred_shifted = y_attack_test_pred + 1\n",
    "    \n",
    "    # Create final predictions\n",
    "    y_test_pred = np.zeros_like(y_test)\n",
    "    y_test_pred[anomaly_indices_test] = y_attack_test_pred_shifted\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(y_test, y_test_pred, average='macro')\n",
    "    test_report = classification_report(y_test, y_test_pred)\n",
    "    test_confusion = confusion_matrix(y_test, y_test_pred)\n",
    "    \n",
    "    print(f\"\\nHybrid model - Test set performance:\")\n",
    "    print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Macro-average precision: {test_precision:.4f}\")\n",
    "    print(f\"Macro-average recall: {test_recall:.4f}\")\n",
    "    print(f\"Macro-average F1-score: {test_f1:.4f}\")\n",
    "    print(\"\\nClassification Report (Test Set):\")\n",
    "    print(test_report)\n",
    "    print(\"\\nConfusion Matrix (Test Set):\")\n",
    "    print(test_confusion)\n",
    "else:\n",
    "    print(\"No anomalies detected in test set by OneClassSVM.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving models...\n",
      "Models saved to /root/autodl-tmp/projects/USL_NSL/notebooks/multi/hybrid/models/hybrid_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Save Trained Models\n",
    "print(\"\\nSaving models...\")\n",
    "import os\n",
    "\n",
    "# Create Paths to Save Models\n",
    "model_dir = '/root/autodl-tmp/projects/USL_NSL/notebooks/multi/hybrid/models'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    print(f\"Created directory: {model_dir}\")\n",
    "\n",
    "models = {\n",
    "    'scaler': scaler,\n",
    "    'anomaly_detector': anomaly_detector,\n",
    "    'class_names': class_names\n",
    "}\n",
    "\n",
    "model_path = '/root/autodl-tmp/projects/USL_NSL/notebooks/multi/hybrid/models/hybrid_model.pkl'\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(models, f)\n",
    "print(f\"Models saved to {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sl-nsl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
