{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries and Setup Paths\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cupy as cp\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# Define paths\n",
    "processed_train_path = '/root/autodl-tmp/projects/USL_NSL/dataset/processed/multi/KDDTrain_processed.csv'\n",
    "processed_test_path = '/root/autodl-tmp/projects/USL_NSL/dataset/processed/multi/KDDTest_processed.csv'\n",
    "train_labels_path = '/root/autodl-tmp/projects/USL_NSL/dataset/processed/multi/KDDTrain_labels.csv'\n",
    "test_labels_path = '/root/autodl-tmp/projects/USL_NSL/dataset/processed/multi/KDDTest_labels.csv'\n",
    "\n",
    "# Load class names mapping\n",
    "preprocessing_path = '/root/autodl-tmp/projects/USL_NSL/dataset/processed/multi/preprocessing_objects.pkl'\n",
    "with open(preprocessing_path, 'rb') as f:\n",
    "    preprocessing_objects = pickle.load(f)\n",
    "    class_names = preprocessing_objects['class_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "\n",
      "Class distribution in training data:\n",
      "Class 0 (Normal Traffic): 67343 samples (53.46%)\n",
      "Class 1 (DOS (Denial of Service)): 45927 samples (36.46%)\n",
      "Class 2 (Probe (Surveillance/Scanning)): 11656 samples (9.25%)\n",
      "Class 3 (R2L (Remote to Local)): 995 samples (0.79%)\n",
      "Class 4 (U2R (User to Root)): 52 samples (0.04%)\n",
      "\n",
      "Dataset shapes:\n",
      "Training set: (100778, 43)\n",
      "Validation set: (25195, 43)\n",
      "Loading complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load and Prepare Data\n",
    "print(\"Loading training data...\")\n",
    "df_train = pd.read_csv(processed_train_path)\n",
    "X = df_train.drop('multiclass_label', axis=1).values\n",
    "y = df_train['multiclass_label'].values\n",
    "\n",
    "# Split training set and validation set (80-20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Display number of samples for each class\n",
    "class_dist = pd.Series(y).value_counts().sort_index()\n",
    "print(\"\\nClass distribution in training data:\")\n",
    "for class_id, count in class_dist.items():\n",
    "    print(f\"Class {class_id} ({class_names[class_id]}): {count} samples ({count/len(y)*100:.2f}%)\")\n",
    "\n",
    "# Display data information\n",
    "print(\"\\nDataset shapes:\")\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(\"Loading complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training multiclass One-Class SVM models with improved parameters and balanced samples...\n",
      "Number of classes: 5\n",
      "Improved nu parameters for each class:\n",
      "Class 0 (Normal Traffic): 0.3500\n",
      "Class 1 (DOS (Denial of Service)): 0.1500\n",
      "Class 2 (Probe (Surveillance/Scanning)): 0.1500\n",
      "Class 3 (R2L (Remote to Local)): 0.1500\n",
      "Class 4 (U2R (User to Root)): 0.1000\n",
      "\n",
      "Balancing training data using SMOTE for minority classes...\n",
      "Original count for Class 0 (Normal Traffic): 53874\n",
      "Original count for Class 1 (DOS (Denial of Service)): 36741\n",
      "Original count for Class 2 (Probe (Surveillance/Scanning)): 9325\n",
      "Original count for Class 3 (R2L (Remote to Local)): 796\n",
      "Original count for Class 4 (U2R (User to Root)): 42\n",
      "\n",
      "SMOTE sampling strategy for minority classes:\n",
      "Class 3 (R2L (Remote to Local)): 796 → 3980 samples\n",
      "Class 4 (U2R (User to Root)): 42 → 420 samples\n",
      "\n",
      "Resampled class distribution:\n",
      "Class 0 (Normal Traffic): 53874 samples (51.63%)\n",
      "Class 1 (DOS (Denial of Service)): 36741 samples (35.21%)\n",
      "Class 2 (Probe (Surveillance/Scanning)): 9325 samples (8.94%)\n",
      "Class 3 (R2L (Remote to Local)): 3980 samples (3.81%)\n",
      "Class 4 (U2R (User to Root)): 420 samples (0.40%)\n",
      "\n",
      "Training model for class 0 (Normal Traffic)...\n",
      "Using 53874 normal samples for training\n",
      "Training completed in 218.70 seconds\n",
      "\n",
      "Training model for class 1 (DOS (Denial of Service))...\n",
      "Using 18370 normal samples and 36741 samples of class 1 for training\n",
      "Normal to attack ratio: 0.5:1\n",
      "Training completed in 94.65 seconds\n",
      "\n",
      "Training model for class 2 (Probe (Surveillance/Scanning))...\n",
      "Using 18650 normal samples and 9325 samples of class 2 for training\n",
      "Normal to attack ratio: 2.0:1\n",
      "Training completed in 19.33 seconds\n",
      "\n",
      "Training model for class 3 (R2L (Remote to Local))...\n",
      "Using 7960 normal samples and 3980 samples of class 3 for training\n",
      "Normal to attack ratio: 2.0:1\n",
      "Training completed in 2.89 seconds\n",
      "\n",
      "Training model for class 4 (U2R (User to Root))...\n",
      "Using 420 normal samples and 420 samples of class 4 for training\n",
      "Normal to attack ratio: 1.0:1\n",
      "Training completed in 0.01 seconds\n",
      "\n",
      "All models have been trained with improved parameters and balanced samples! Total training time: 335.58 seconds\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Training multiclass One-Class SVM models with improved parameters and balanced samples\n",
    "print(\"\\nTraining multiclass One-Class SVM models with improved parameters and balanced samples...\")\n",
    "\n",
    "# Get number of classes\n",
    "n_classes = len(np.unique(y))\n",
    "print(f\"Number of classes: {n_classes}\")\n",
    "\n",
    "# Adjust nu parameters based on the improved approach from IF model\n",
    "nu_params = {\n",
    "    0: 0.35,  # Increased from 0.1 to improve normal traffic detection\n",
    "    1: 0.15,  # Slightly reduced from 0.2\n",
    "    2: 0.15,  # Slightly reduced from 0.2\n",
    "    3: 0.15,  # Slightly reduced from 0.2\n",
    "    4: 0.10   # Significantly reduced from 0.2 to prevent over-prediction\n",
    "}\n",
    "        \n",
    "print(\"Improved nu parameters for each class:\")\n",
    "for i in range(n_classes):\n",
    "    print(f\"Class {i} ({class_names[i]}): {nu_params[i]:.4f}\")\n",
    "\n",
    "# Balance training samples using SMOTE for minority classes only\n",
    "print(\"\\nBalancing training data using SMOTE for minority classes...\")\n",
    "\n",
    "# Get original class counts\n",
    "original_counts = {}\n",
    "for i in range(n_classes):\n",
    "    original_counts[i] = len(X_train[y_train == i])\n",
    "    print(f\"Original count for Class {i} ({class_names[i]}): {original_counts[i]}\")\n",
    "\n",
    "# Define sampling strategy to balance classes\n",
    "sampling_strategy = {}\n",
    "for i in range(n_classes):\n",
    "    if i == 3:  # R2L\n",
    "        # Increase R2L samples 5x but cap at 1/5 of normal samples\n",
    "        sampling_strategy[i] = min(original_counts[0]//5, original_counts[i] * 5)\n",
    "    elif i == 4:  # U2R\n",
    "        # Increase U2R samples 10x but cap at 1/10 of normal samples\n",
    "        sampling_strategy[i] = min(original_counts[0]//10, original_counts[i] * 10)\n",
    "    else:\n",
    "        # Keep other classes unchanged by not including them in the strategy\n",
    "        # SMOTE will only oversample classes specified in the strategy\n",
    "        pass\n",
    "\n",
    "print(\"\\nSMOTE sampling strategy for minority classes:\")\n",
    "for class_id, target_count in sampling_strategy.items():\n",
    "    print(f\"Class {class_id} ({class_names[class_id]}): {original_counts[class_id]} → {target_count} samples\")\n",
    "\n",
    "# Apply SMOTE only to minority classes\n",
    "if sampling_strategy:  # Only apply if we have classes to oversample\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy, random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Display resampled class distribution\n",
    "    resampled_class_dist = pd.Series(y_resampled).value_counts().sort_index()\n",
    "    print(\"\\nResampled class distribution:\")\n",
    "    for class_id, count in resampled_class_dist.items():\n",
    "        print(f\"Class {class_id} ({class_names[class_id]}): {count} samples ({count/len(y_resampled)*100:.2f}%)\")\n",
    "else:\n",
    "    # If no oversampling needed, use original data\n",
    "    X_resampled, y_resampled = X_train, y_train\n",
    "    print(\"\\nNo oversampling applied, using original data.\")\n",
    "\n",
    "# Train a One-Class SVM model for each class with improved approach\n",
    "oc_svms = []\n",
    "training_times = []\n",
    "\n",
    "for i in range(n_classes):\n",
    "    print(f\"\\nTraining model for class {i} ({class_names[i]})...\")\n",
    "    \n",
    "    if i == 0:\n",
    "        # For normal class, use all normal samples\n",
    "        current_class_samples = X_resampled[y_resampled == i]\n",
    "        print(f\"Using {len(current_class_samples)} normal samples for training\")\n",
    "    else:\n",
    "        # For attack classes, use a balanced approach:\n",
    "        # 1. Select samples from the normal class\n",
    "        # 2. Select samples from the current attack class\n",
    "        # 3. Use a more balanced ratio between normal and attack samples\n",
    "        \n",
    "        normal_samples = X_resampled[y_resampled == 0]\n",
    "        attack_samples = X_resampled[y_resampled == i]\n",
    "        \n",
    "        # Use a more balanced ratio between normal and attack samples\n",
    "        if i == 1:  # DOS (majority attack class)\n",
    "            # For DOS, use fewer normal samples to balance\n",
    "            ratio = 0.5  # Use 1:2 ratio (normal:DOS)\n",
    "            n_normal = min(len(normal_samples), int(len(attack_samples) * ratio))\n",
    "        elif i == 4:  # U2R (most imbalanced class)\n",
    "            ratio = 1.0  # Use 1:1 ratio for U2R\n",
    "            n_normal = min(len(normal_samples), int(len(attack_samples) * ratio))\n",
    "        else:\n",
    "            ratio = 2.0  # Use 2:1 ratio for other attack types\n",
    "            n_normal = min(len(normal_samples), int(len(attack_samples) * ratio))\n",
    "            \n",
    "        # Select normal samples randomly\n",
    "        normal_indices = np.random.choice(len(normal_samples), n_normal, replace=False)\n",
    "        selected_normal = normal_samples[normal_indices]\n",
    "        \n",
    "        # Combine samples\n",
    "        current_class_samples = np.vstack([selected_normal, attack_samples])\n",
    "        print(f\"Using {len(selected_normal)} normal samples and {len(attack_samples)} samples of class {i} for training\")\n",
    "        print(f\"Normal to attack ratio: {len(selected_normal)/len(attack_samples):.1f}:1\")\n",
    "    \n",
    "    # Train the One-Class SVM model for the current class with improved parameters\n",
    "    start_time = time.time()\n",
    "    oc_svm = OneClassSVM(\n",
    "        kernel='rbf',\n",
    "        nu=nu_params[i],\n",
    "        gamma='scale',\n",
    "        cache_size=1000,  # Increased cache size for better performance\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    oc_svm.fit(current_class_samples)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    training_times.append(training_time)\n",
    "    \n",
    "    print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "    oc_svms.append(oc_svm)\n",
    "\n",
    "print(f\"\\nAll models have been trained with improved parameters and balanced samples! Total training time: {sum(training_times):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on training set...\n",
      "\n",
      "Training set accuracy: 0.5559\n",
      "Macro-average precision: 0.6493\n",
      "Macro-average recall: 0.3444\n",
      "Macro-average F1-score: 0.3292\n",
      "\n",
      "Classification Report (Training Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.99      0.70     53874\n",
      "           1       0.99      0.02      0.04     36741\n",
      "           2       0.99      0.17      0.29      9325\n",
      "           3       0.40      0.35      0.37       796\n",
      "           4       0.32      0.19      0.24        42\n",
      "\n",
      "    accuracy                           0.56    100778\n",
      "   macro avg       0.65      0.34      0.33    100778\n",
      "weighted avg       0.75      0.56      0.42    100778\n",
      "\n",
      "\n",
      "Confusion Matrix (Training Set):\n",
      "[[53418     7    14   419    16]\n",
      " [36024   717     0     0     0]\n",
      " [ 7728     0  1597     0     0]\n",
      " [  517     0     0   278     1]\n",
      " [   33     0     0     1     8]]\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Evaluate on Training Set\n",
    "print(\"\\nEvaluating on training set...\")\n",
    "\n",
    "# Calculate anomaly scores for each class\n",
    "train_scores = np.zeros((X_train.shape[0], n_classes))\n",
    "\n",
    "for i in range(n_classes):\n",
    "    # Calculate anomaly scores for the i-th class\n",
    "    train_scores[:, i] = -oc_svms[i].score_samples(X_train)  # Negative sign makes lower scores indicate more likely to belong to that class\n",
    "\n",
    "# Predict the class with the lowest anomaly score\n",
    "train_predictions = np.argmin(train_scores, axis=1)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "train_precision, train_recall, train_f1, _ = precision_recall_fscore_support(y_train, train_predictions, average='macro')\n",
    "train_report = classification_report(y_train, train_predictions)\n",
    "train_confusion = confusion_matrix(y_train, train_predictions)\n",
    "\n",
    "print(f\"\\nTraining set accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Macro-average precision: {train_precision:.4f}\")\n",
    "print(f\"Macro-average recall: {train_recall:.4f}\")\n",
    "print(f\"Macro-average F1-score: {train_f1:.4f}\")\n",
    "print(\"\\nClassification Report (Training Set):\")\n",
    "print(train_report)\n",
    "print(\"\\nConfusion Matrix (Training Set):\")\n",
    "print(train_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on validation set...\n",
      "\n",
      "Validation set accuracy: 0.5550\n",
      "Macro-average precision: 0.6331\n",
      "Macro-average recall: 0.3765\n",
      "Macro-average F1-score: 0.3402\n",
      "\n",
      "Classification Report (Validation Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.99      0.70     13469\n",
      "           1       1.00      0.02      0.04      9186\n",
      "           2       0.99      0.17      0.29      2331\n",
      "           3       0.36      0.40      0.38       199\n",
      "           4       0.27      0.30      0.29        10\n",
      "\n",
      "    accuracy                           0.55     25195\n",
      "   macro avg       0.63      0.38      0.34     25195\n",
      "weighted avg       0.75      0.55      0.42     25195\n",
      "\n",
      "\n",
      "Confusion Matrix (Validation Set):\n",
      "[[13314     0     5   142     8]\n",
      " [ 9001   185     0     0     0]\n",
      " [ 1929     0   401     1     0]\n",
      " [  119     0     0    80     0]\n",
      " [    7     0     0     0     3]]\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Evaluate on Validation Set\n",
    "print(\"\\nEvaluating on validation set...\")\n",
    "\n",
    "# Calculate anomaly scores for each class\n",
    "val_scores = np.zeros((X_val.shape[0], n_classes))\n",
    "\n",
    "for i in range(n_classes):\n",
    "    # Calculate anomaly scores for the i-th class\n",
    "    val_scores[:, i] = -oc_svms[i].score_samples(X_val)  # Negative sign makes lower scores indicate more likely to belong to that class\n",
    "\n",
    "# Predict the class with the lowest anomaly score\n",
    "val_predictions = np.argmin(val_scores, axis=1)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(y_val, val_predictions, average='macro')\n",
    "val_report = classification_report(y_val, val_predictions)\n",
    "val_confusion = confusion_matrix(y_val, val_predictions)\n",
    "\n",
    "print(f\"\\nValidation set accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Macro-average precision: {val_precision:.4f}\")\n",
    "print(f\"Macro-average recall: {val_recall:.4f}\")\n",
    "print(f\"Macro-average F1-score: {val_f1:.4f}\")\n",
    "print(\"\\nClassification Report (Validation Set):\")\n",
    "print(val_report)\n",
    "print(\"\\nConfusion Matrix (Validation Set):\")\n",
    "print(val_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "Class distribution in test data:\n",
      "Class 0 (Normal Traffic): 9711 samples (43.08%)\n",
      "Class 1 (DOS (Denial of Service)): 7458 samples (33.08%)\n",
      "Class 2 (Probe (Surveillance/Scanning)): 2421 samples (10.74%)\n",
      "Class 3 (R2L (Remote to Local)): 2887 samples (12.81%)\n",
      "Class 4 (U2R (User to Root)): 67 samples (0.30%)\n",
      "\n",
      "Test set accuracy: 0.4335\n",
      "Macro-average precision: 0.4252\n",
      "Macro-average recall: 0.3201\n",
      "Macro-average F1-score: 0.2372\n",
      "\n",
      "Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.99      0.60      9711\n",
      "           1       0.18      0.00      0.00      7458\n",
      "           2       0.90      0.04      0.08      2421\n",
      "           3       0.17      0.00      0.00      2887\n",
      "           4       0.45      0.57      0.50        67\n",
      "\n",
      "    accuracy                           0.43     22544\n",
      "   macro avg       0.43      0.32      0.24     22544\n",
      "weighted avg       0.36      0.43      0.27     22544\n",
      "\n",
      "\n",
      "Confusion Matrix (Test Set):\n",
      "[[9626   37    4   14   30]\n",
      " [7443    8    3    4    0]\n",
      " [2325    0   96    0    0]\n",
      " [2863    0    4    4   16]\n",
      " [  27    0    0    2   38]]\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Evaluate on Test Set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "\n",
    "# Load test data\n",
    "df_test = pd.read_csv(processed_test_path)\n",
    "X_test = df_test.drop('multiclass_label', axis=1).values\n",
    "y_test = df_test['multiclass_label'].values\n",
    "\n",
    "# Display distribution of classes in test data\n",
    "test_class_dist = pd.Series(y_test).value_counts().sort_index()\n",
    "print(\"\\nClass distribution in test data:\")\n",
    "for class_id, count in test_class_dist.items():\n",
    "    print(f\"Class {class_id} ({class_names[class_id]}): {count} samples ({count/len(y_test)*100:.2f}%)\")\n",
    "\n",
    "# Calculate anomaly scores for each class\n",
    "test_scores = np.zeros((X_test.shape[0], n_classes))\n",
    "\n",
    "for i in range(n_classes):\n",
    "    # Calculate anomaly scores for the i-th class\n",
    "    test_scores[:, i] = -oc_svms[i].score_samples(X_test)\n",
    "\n",
    "# Predict the class with the lowest anomaly score\n",
    "test_predictions = np.argmin(test_scores, axis=1)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(y_test, test_predictions, average='macro')\n",
    "test_report = classification_report(y_test, test_predictions)\n",
    "test_confusion = confusion_matrix(y_test, test_predictions)\n",
    "\n",
    "print(f\"\\nTest set accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Macro-average precision: {test_precision:.4f}\")\n",
    "print(f\"Macro-average recall: {test_recall:.4f}\")\n",
    "print(f\"Macro-average F1-score: {test_f1:.4f}\")\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(test_report)\n",
    "print(\"\\nConfusion Matrix (Test Set):\")\n",
    "print(test_confusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sl-nsl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
